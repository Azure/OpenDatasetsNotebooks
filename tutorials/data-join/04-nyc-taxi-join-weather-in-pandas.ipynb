{"cells":[{"cell_type":"markdown","source":["Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}},{"cell_type":"markdown","source":["# Tutorial: Load TAXI data and enrich it with Weather data in Pandas DataFrame"],"metadata":{}},{"cell_type":"markdown","source":["Install azureml-opendatasets package"],"metadata":{}},{"cell_type":"code","source":["!pip uninstall -y azureml-opendatasets\n!pip install azureml-opendatasets"],"metadata":{"scrolled":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Begin by creating a dataframe to hold the taxi data. When working in a non-Spark environment, Open Datasets only allows downloading one month of data at a time with certain classes to avoid MemoryError with large datasets. To download 2 months of taxi data, iteratively fetch one month at a time, and before appending it to green_taxi_df randomly sample 2000 records from the specific month to avoid bloating the dataframe."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nfrom azureml.opendatasets import NycTlcGreen\n\n\ngreen_taxi_df = pd.DataFrame([])\nstart = datetime.strptime(\"1/1/2016\", \"%m/%d/%Y\")\nend = datetime.strptime(\"1/31/2016\", \"%m/%d/%Y\")\n\nfor sample_month in range(2):\n    temp_df_green = NycTlcGreen(\n        start + relativedelta(months=sample_month),\n        end + relativedelta(months=sample_month)).to_pandas_dataframe()\n    green_taxi_df = green_taxi_df.append(temp_df_green.sample(2000))"],"metadata":{"scrolled":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ActivityStarted, to_pandas_dataframe\nActivityStarted, to_pandas_dataframe_in_worker\nTarget paths: [&apos;/puYear=2016/puMonth=1/&apos;]\nLooking for parquet files...\nReading them into Pandas dataframe...\nReading green/puYear=2016/puMonth=1/part-00119-tid-6037743401120983271-619c4849-c957-4290-a1b8-66832cb385b6-12538.c000.snappy.parquet under container nyctlc\nDone.\nActivityCompleted: Activity=to_pandas_dataframe_in_worker, HowEnded=Success, Duration=5969.23 [ms]\nActivityCompleted: Activity=to_pandas_dataframe, HowEnded=Success, Duration=5970.56 [ms]\nActivityStarted, to_pandas_dataframe\nActivityStarted, to_pandas_dataframe_in_worker\nTarget paths: [&apos;/puYear=2016/puMonth=2/&apos;]\nLooking for parquet files...\nReading them into Pandas dataframe...\nReading green/puYear=2016/puMonth=2/part-00060-tid-6037743401120983271-619c4849-c957-4290-a1b8-66832cb385b6-12479.c000.snappy.parquet under container nyctlc\nDone.\nActivityCompleted: Activity=to_pandas_dataframe_in_worker, HowEnded=Success, Duration=6457.69 [ms]\nActivityCompleted: Activity=to_pandas_dataframe, HowEnded=Success, Duration=6459.1 [ms]\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Save a copy of the raw_columns name list for clean up at the last step."],"metadata":{}},{"cell_type":"code","source":["raw_columns = list(green_taxi_df.columns)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["<font color='red'>Get mean values of pickupLatitude and pickupLongitude</font>"],"metadata":{}},{"cell_type":"code","source":["info = green_taxi_df.describe()\ninfo['pickupLatitude']['mean'], info['pickupLongitude']['mean']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>(40.654190485000612, -73.770879159927375)\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Drop the rows that both lat/long are NaN, especially all columns in the first row are NaN."],"metadata":{}},{"cell_type":"code","source":["green_taxi_df = green_taxi_df.dropna(how='all', subset=['lpepPickupDatetime', 'pickupLatitude', 'pickupLongitude'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Make all pickupLatitude and pickupLongitude be the center location of the city."],"metadata":{}},{"cell_type":"code","source":["def set_lat(x):\n    return info['pickupLatitude']['mean']\ndef set_long(x):\n    return info['pickupLongitude']['mean']\ngreen_taxi_df['pickupLatitude'] = green_taxi_df[['pickupLatitude']].apply(set_lat, axis=1)\ngreen_taxi_df['pickupLongitude'] = green_taxi_df[['pickupLongitude']].apply(set_long, axis=1)\ngreen_taxi_df.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>\n         vendorID  lpepPickupDatetime    ...    totalAmount  tripType\n793496          2 2016-01-16 21:07:48    ...          19.30       1.0\n373142          2 2016-01-08 10:11:38    ...          37.80       1.0\n402180          2 2016-01-08 21:44:08    ...          13.50       1.0\n1357877         1 2016-01-04 21:59:23    ...          17.80       1.0\n284994          2 2016-01-25 10:51:16    ...          11.16       1.0\n\n[5 rows x 23 columns]\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["The original index can fail the initialization of class LocationTimeCustomerData at below, so this is a workaround to add a monotonically increasing id column."],"metadata":{}},{"cell_type":"code","source":["green_taxi_df['idx'] = list(range(len(green_taxi_df.index)))\ngreen_taxi_df_idx = green_taxi_df.set_index('idx')\ngreen_taxi_df_idx.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n     vendorID  lpepPickupDatetime    ...    totalAmount  tripType\nidx                                  ...                         \n0           2 2016-01-16 21:07:48    ...          19.30       1.0\n1           2 2016-01-08 10:11:38    ...          37.80       1.0\n2           2 2016-01-08 21:44:08    ...          13.50       1.0\n3           1 2016-01-04 21:59:23    ...          17.80       1.0\n4           2 2016-01-25 10:51:16    ...          11.16       1.0\n\n[5 rows x 23 columns]\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Initialize LocationTimeCustomerData using pandas dataframe green_taxi."],"metadata":{}},{"cell_type":"code","source":["# This is a package in preview.\n\nfrom azureml.opendatasets.accessories.location_data import LatLongColumn\nfrom azureml.opendatasets.accessories.location_time_customer_data \\\n    import LocationTimeCustomerData\nfrom azureml.opendatasets import NoaaIsdWeather\n\n\ngreen_taxi = LocationTimeCustomerData(\n    green_taxi_df_idx,\n    LatLongColumn('pickupLatitude', 'pickupLongitude'),\n    'lpepPickupDatetime')"],"metadata":{"scrolled":true},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Initialize NoaaIsdWeather class, get enricher from it, and enrich the taxi data without aggregation"],"metadata":{}},{"cell_type":"code","source":["weather = NoaaIsdWeather(\n    cols=[\"temperature\", \"precipTime\", \"precipDepth\", \"snowDepth\"],\n    start_date=datetime(2016, 1, 1, 0, 0),\n    end_date=datetime(2016, 2, 28, 23, 59))\nweather_enricher = weather.get_enricher()\nnew_green_taxi, processed_weather = weather_enricher.enrich_customer_data_no_agg(\n    customer_data_object=green_taxi,\n    location_match_granularity=1,\n    time_round_granularity='day')"],"metadata":{"scrolled":false},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ActivityStarted, get_enricher\nActivityCompleted: Activity=get_enricher, HowEnded=Success, Duration=1.69 [ms]\nActivityStarted, enrich_customer_data_no_agg\nActivityStarted, enrich\nTarget paths: [&apos;/year=2016/month=1/&apos;, &apos;/year=2016/month=2/&apos;]\nLooking for parquet files...\nReading them into Pandas dataframe...\nReading ISDWeather/year=2016/month=1/part-00005-tid-6700213360605767691-4491b75c-f137-489b-b5df-4204b9326fda-110.c000.snappy.parquet under container isdweatherdatacontainer\nReading ISDWeather/year=2016/month=2/part-00011-tid-6700213360605767691-4491b75c-f137-489b-b5df-4204b9326fda-116.c000.snappy.parquet under container isdweatherdatacontainer\nDone.\nActivityStarted, _get_closest_location_kdTree\nActivityCompleted: Activity=_get_closest_location_kdTree, HowEnded=Success, Duration=307.59 [ms]\nActivityCompleted: Activity=enrich, HowEnded=Success, Duration=168338.18 [ms]\nActivityCompleted: Activity=enrich_customer_data_no_agg, HowEnded=Success, Duration=168624.07 [ms]\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["Preview the pandas dataframe new_green_taxi.data"],"metadata":{}},{"cell_type":"code","source":["new_green_taxi.data.head(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">10</span><span class=\"ansired\">]: </span>\n   vendorID           ...           customer_join_timeutf6j\n0         2           ...                        2016-01-16\n1         2           ...                        2016-01-08\n2         2           ...                        2016-01-08\n\n[3 rows x 25 columns]\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["Define a dict `aggregations` to define how to aggregate each field at a hour level. For `snowDepth` and `temperature` we'll take the mean and for `precipTime` and `precipDepth` we'll take the hourly maximum. Use the groupby() function along with the aggregations to group data."],"metadata":{}},{"cell_type":"code","source":["aggregations = {\n    \"snowDepth\": \"mean\",\n    \"precipTime\": \"max\",\n    \"temperature\": \"mean\",\n    \"precipDepth\": \"max\"}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["The keys (`public_rankgroup`, `public_join_time`, `customer_rankgroup`, `customer_join_time`) used by groupby() and later merge() must be hacked here due to the current design."],"metadata":{}},{"cell_type":"code","source":["public_rankgroup = processed_weather.id\n\npublic_join_time = [\n    s for s in list(processed_weather.data.columns)\n    if s.startswith('ds_join_time')][0]\n\ncustomer_rankgroup = weather_enricher.location_selector.customer_rankgroup\n\ncustomer_join_time = [\n    s for s in list(new_green_taxi.data.columns)\n    if type(s) is str and s.startswith('customer_join_time')][0]\n\nweather_df_grouped = processed_weather.data.groupby(by=[public_rankgroup, public_join_time]).agg(aggregations)\nweather_df_grouped.head(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n                                         snowDepth     ...       temperature\npublic_rankgroupe8k4d ds_join_timetud1w                ...                  \n1                     2016-01-01               0.0     ...          5.590625\n                      2016-01-02               0.0     ...          3.087500\n                      2016-01-03               0.0     ...          4.668750\n\n[3 rows x 4 columns]\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["Join the final dataframe, and preview the joined result."],"metadata":{}},{"cell_type":"code","source":["joined_dataset = new_green_taxi.data.merge(\n    weather_df_grouped,\n    left_on=[customer_rankgroup, customer_join_time],\n    right_on=[public_rankgroup, public_join_time],\n    how='left')\n\nfinal_df = joined_dataset[raw_columns + [\n    \"temperature\", \"precipTime\", \"precipDepth\", \"snowDepth\"]]\nfinal_df.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">13</span><span class=\"ansired\">]: </span>\n   vendorID  lpepPickupDatetime    ...     precipDepth  snowDepth\n0         2 2016-01-16 21:07:48    ...            79.0   0.000000\n1         2 2016-01-08 10:11:38    ...             0.0   0.000000\n2         2 2016-01-08 21:44:08    ...             0.0   0.000000\n3         1 2016-01-04 21:59:23    ...             0.0   0.000000\n4         2 2016-01-25 10:51:16    ...             0.0  64.888889\n\n[5 rows x 27 columns]\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["Check the join success rate."],"metadata":{}},{"cell_type":"code","source":["final_df.info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nInt64Index: 4000 entries, 0 to 3999\nData columns (total 27 columns):\nvendorID                4000 non-null int32\nlpepPickupDatetime      4000 non-null datetime64[ns]\nlpepDropoffDatetime     4000 non-null datetime64[ns]\npassengerCount          4000 non-null int32\ntripDistance            4000 non-null float64\npuLocationId            0 non-null object\ndoLocationId            0 non-null object\npickupLongitude         4000 non-null float64\npickupLatitude          4000 non-null float64\ndropoffLongitude        4000 non-null float64\ndropoffLatitude         4000 non-null float64\nrateCodeID              4000 non-null int32\nstoreAndFwdFlag         4000 non-null object\npaymentType             4000 non-null int32\nfareAmount              4000 non-null float64\nextra                   4000 non-null float64\nmtaTax                  4000 non-null float64\nimprovementSurcharge    4000 non-null object\ntipAmount               4000 non-null float64\ntollsAmount             4000 non-null float64\nehailFee                0 non-null float64\ntotalAmount             4000 non-null float64\ntripType                4000 non-null float64\ntemperature             4000 non-null float64\nprecipTime              4000 non-null float64\nprecipDepth             4000 non-null float64\nsnowDepth               4000 non-null float64\ndtypes: datetime64[ns](2), float64(17), int32(4), object(4)\nmemory usage: 812.5+ KB\n</div>"]}}],"execution_count":30}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.7","nbconvert_exporter":"python","file_extension":".py"},"name":"04-nyc-taxi-join-weather-in-pandas","notebookId":2741195231538751},"nbformat":4,"nbformat_minor":0}
